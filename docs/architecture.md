# ModernBERT 医学实体关系提取模型架构设计

## 1. 总体设计理念
本项目旨在构建一个端到端的医学文本实体关系提取模型，核心目标是直接从文本中预测语义三元组（Subject-Predicate-Object, SPO）。

## 2. 模型架构
### 2.1 基础预训练模型
- 使用 ModernBERT 作为特征提取器
- 模型配置在 `config.yaml` 中定义

### 2.2 端到端 SPO 提取模块
#### 2.2.1 关系模式预测
- 直接预测文本中的关系模式
- 输出维度：关系模式数量 + 1（0 表示无关系）
- 使用多标签分类方法

#### 2.2.2 实体跨度识别
- 联合预测主语和宾语的起始、结束位置
- 使用二分类（是/否）确定实体边界
- 不再单独进行实体类型分类

## 3. 数据处理流程
### 3.1 输入表示
- 使用 ModernBERT 分词器
- 固定最大序列长度
- 保留原始实体类型信息

### 3.2 标签映射
- 关系模式映射：
  - 从 1 开始编号
  - 0 预留给"无关系"
- 不再进行实体类型的显式映射

## 4. 训练策略
### 4.1 损失函数
- SPO 模式损失：交叉熵
- 实体跨度损失：二值交叉熵
- 联合优化，避免多阶段训练

### 4.2 评估指标
- 精确率（Precision）
- 召回率（Recall）
- F1 分数
- 基于完整 SPO 三元组的精确匹配

## 5. 推理流程
### 5.1 候选三元组生成
- 遍历所有可能的主语起始位置
- 对每个主语位置：
  1. 预测关系模式
  2. 识别主语跨度
  3. 识别宾语跨度
- 过滤低概率预测

### 5.2 后处理
- 去重
- 置信度阈值过滤

## 6. 系统约束与假设
- 假设输入文本已经进行了必要的预处理
- 模型不区分实体类型，专注于关系提取
- 支持多个关系模式的同时预测

## 7. 性能与可扩展性
- 模型设计追求计算效率
- 预留模型结构调整的灵活性
- 支持增量学习和迁移学习

## 8. 局限性
- 依赖高质量的训练语料
- 对长文本和复杂语境的处理能力有限
- 需要持续的模型微调和评估

## 9. 未来改进方向
- 引入注意力机制增强
- 探索更复杂的实体和关系联合建模
- 集成外部知识图谱

## 10. 模型权重与组件说明

### 10.1 新增的模型组件

为了实现医学文本的实体关系提取任务，我们在原始 ModernBERT 模型的基础上添加了以下组件：

1. **实体范围预测头**：
   ```
   - span_classifier.weight
   - span_classifier.bias
   ```
   用于预测文本中的实体跨度和边界。

2. **SPO关系模式分类头**：
   ```
   - spo_pattern_classifier.weight
   - spo_pattern_classifier.bias
   ```
   用于预测实体之间的关系模式。

### 10.2 模型权重加载注意事项

#### 10.2.1 新增组件的权重初始化
这些组件在加载预训练权重时会显示为"缺少的键"，这是正常的。它们是任务特定的组件，会在训练过程中从随机初始化开始学习。

#### 10.2.2 未使用的预训练组件
原始 ModernBERT 模型中的一些预训练任务组件在我们的任务中不会使用：

1. MLM（掩码语言模型）预测头：
   ```
   - head.dense.weight
   - head.norm.weight
   ```

2. MLM 解码器：
   ```
   - decoder.bias
   ```
这些组件在加载模型时会显示为"未使用的键"，这是正常的。

### 10.3 模型加载与配置建议

#### 10.3.1 模型参数管理
- 模型的固定参数会从预训练模型的 `config.json` 中自动读取
- **不要** 在配置文件中覆盖模型的固定参数

#### 10.3.2 序列长度与性能优化
1. **序列长度**
   - 模型支持最大 8192 tokens
   - 建议根据实际需求和硬件限制设置 `max_seq_length`
   - 使用较长序列时需要相应减小 batch size

2. **性能优化技巧**
   - 训练时可以禁用 cache (`use_cache: false`)
   - 使用梯度累积来模拟更大的 batch size
   - 可以使用 `freeze_backbone` 选择是否冻结预训练模型参数

#### 10.3.3 模型输入特点
- 不需要 `token_type_ids`
- 使用 `input_ids` 和 `attention_mask` 作为主要输入

### 10.4 模型组件设计原则

1. **最小化额外参数**
   - 仅添加必要的任务特定组件
   - 尽量减少对预训练模型的修改

2. **保持模块独立性**
   - 新增组件与预训练模型解耦
   - 便于模型的可扩展性和维护

3. **灵活的特征适配**
   - 利用预训练模型的通用语言表示
   - 通过轻量级分类器实现特定任务的精准预测
